"""
Minimal PDF Text Extractor - Standard Library Only

This module extracts plain text from simple, text-based PDFs using only Python's
standard library. It does NOT use any third-party libraries (no pdfplumber, PyPDF, etc).

SUPPORTED:
  - Simple text-based PDFs (e.g., generated by modern tools)
  - PDFs with extractable text streams

UNSUPPORTED (will raise clear errors):
  - Scanned PDFs (image-based content)
  - Encrypted PDFs
  - Complex multi-column layouts (best-effort only)
  - PDFs with embedded fonts/graphics as text

APPROACH:
  1. Read PDF as binary
  2. Find text streams (BT...ET markers)
  3. Extract string objects (both literal and hex-encoded)
  4. Decode text and return as plain string

WHY NO LIBRARIES?
  - The task explicitly forbids third-party libraries
  - For simple PDFs, basic text extraction via regex/binary parsing is sufficient
  - This demonstrates understanding of PDF structure without dependencies

LIMITATIONS & HONESTY:
  - Complex PDFs may yield garbled text
  - Layout, fonts, and positioning are ignored (intentional)
  - This is a bonus feature, not production-ready
"""

import re
import logging
import io
import zlib
import unicodedata
import shutil
import platform
import os
from typing import Optional

logger = logging.getLogger(__name__)


class PDFExtractionError(Exception):
    """Raised when PDF text extraction fails."""
    pass


def _configure_tesseract(pytesseract_module: object) -> None:
    if shutil.which("tesseract") is not None:
        return
    if platform.system().lower() != "windows":
        return
    candidates = [
        r"C:\Program Files\Tesseract-OCR\tesseract.exe",
        r"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe",
    ]
    for p in candidates:
        if os.path.isfile(p):
            try:
                pytesseract_module.pytesseract.tesseract_cmd = p  # type: ignore[attr-defined]
            except Exception:
                pass
            return


def extract_text_from_pdf(file_bytes: bytes) -> str:
    text, _ = extract_text_from_pdf_with_status(file_bytes)
    return text


def extract_text_from_pdf_with_status(file_bytes: bytes) -> tuple[str, str]:
    """
    Extract plain text from a PDF using only standard library.
    
    For best results, PDFs should be text-based and not scanned.
    This uses a multi-strategy approach to handle various PDF types.

    Args:
        file_bytes: PDF file content as bytes

    Returns:
        Extracted text (plain string, no formatting)

    Raises:
        PDFExtractionError: If PDF is unsupported or corrupted
    """
    try:
        min_valid_text_score = 0.65
        min_valid_ocr_score = 0.55

        if not file_bytes.startswith(b'%PDF'):
            raise PDFExtractionError(
                "Not a valid PDF file (missing %PDF header). "
                "Please check that the file is a PDF."
            )

        pdf_text = file_bytes.decode('iso-8859-1', errors='ignore')

        if '/Encrypt' in pdf_text:
            raise PDFExtractionError(
                "PDF is encrypted. Encrypted PDFs are not supported. "
                "Please use an unencrypted PDF."
            )

        hybrid = _extract_text_with_pymupdf_hybrid(file_bytes)
        if hybrid is not None:
            return hybrid

        candidates: list[tuple[str, str]] = []

        extracted_text = _extract_text_with_pypdf(file_bytes)
        if extracted_text:
            candidates.append((extracted_text, "Text-based PDF detected — extracted text"))

        extracted_text = _extract_text_from_objects(file_bytes, pdf_text)
        if extracted_text:
            candidates.append((extracted_text, "Text-based PDF detected — extracted text"))

        extracted_text = _extract_text_streams(pdf_text)
        if extracted_text:
            candidates.append((extracted_text, "Text-based PDF detected — extracted text"))

        best_text = ""
        best_status = "Text-based PDF detected — extracted text"
        best_score = 0.0
        for t, status in candidates:
            normalized = _normalize_text_for_preview(t)
            score = _readability_score(normalized)
            if score > best_score:
                best_score = score
                best_text = normalized
                best_status = status

        if best_text and best_score >= min_valid_text_score:
            return best_text, best_status

        is_scanned = _is_likely_scanned_pdf(pdf_text, best_text)
        if is_scanned or best_score < min_valid_text_score:
            ocr_text = _ocr_text_from_pdf(file_bytes)
            ocr_text = _normalize_text_for_preview(ocr_text)
            if ocr_text and _readability_score(ocr_text) >= min_valid_ocr_score:
                if is_scanned:
                    return ocr_text, "Scanned PDF detected — OCR applied"
                return ocr_text, "Embedded fonts detected — OCR applied"

        raise PDFExtractionError(
            "Could not extract readable text from this PDF. "
            "If this is a scanned PDF or uses embedded fonts, OCR is required."
        )

    except PDFExtractionError:
        raise
    except Exception as e:
        raise PDFExtractionError(f"Unexpected error during PDF extraction: {e}")


def _extract_text_from_objects(file_bytes: bytes, pdf_text: str) -> str:
    """
    Extract text from PDF object dictionary entries.
    """
    try:
        texts = []
        
        # Pattern: find content in parentheses within objects
        obj_pattern = r'obj.*?\((.*?)\).*?endobj'
        for match in re.finditer(obj_pattern, pdf_text, re.DOTALL):
            text = match.group(1)
            clean = _clean_text(text)
            if clean and len(clean) > 2:
                texts.append(clean)
        
        return ' '.join(texts)
    except Exception:
        return ''


def _extract_readable_text(file_bytes: bytes) -> str:
    """
    Extract readable ASCII text from PDF as fallback.
    """
    readable = []
    current = []
    
    for byte in file_bytes:
        # Only process printable ASCII characters
        if 32 <= byte <= 126:
            current.append(chr(byte))
        else:
            if len(current) > 3:
                text = ''.join(current)
                # Filter for mostly text (not commands)
                if not any(x in text for x in ['stream', 'endstream', '<<', '>>', 'obj', 'endobj', 'xref']):
                    if len([c for c in text if c.isalpha()]) > len(text) * 0.25:
                        readable.append(text)
            current = []
    
    return ' '.join(readable)


def _clean_text(text: str) -> str:
    """Clean extracted text from escape sequences."""
    text = _unescape_pdf_string(text)
    text = ''.join(c for c in text if c.isprintable() or c.isspace())
    return text.strip()


def _normalize_extracted_text(text: str) -> str:
    return _normalize_text_for_preview(text)


def _normalize_text_for_preview(text: str) -> str:
    if not text:
        return ""
    text = text.replace("\r\n", "\n").replace("\r", "\n")
    text = unicodedata.normalize("NFKC", text)
    out = []
    for ch in text:
        o = ord(ch)
        if o == 0:
            continue
        if 0xE000 <= o <= 0xF8FF or 0xF0000 <= o <= 0xFFFFD or 0x100000 <= o <= 0x10FFFD:
            out.append(" ")
            continue
        if ch.isprintable() or ch in "\n\t ":
            out.append(ch)
    text = "".join(out)
    text = text.replace("\t", " ")
    text = re.sub(r"[ ]{2,}", " ", text)
    text = re.sub(r"\n{3,}", "\n\n", text)
    return text.strip()


def _is_reasonably_readable(text: str) -> bool:
    return _readability_score(text) >= 0.55


def _extract_text_with_pypdf(file_bytes: bytes) -> str:
    try:
        from pypdf import PdfReader  # type: ignore
    except Exception:
        return ""

    try:
        reader = PdfReader(io.BytesIO(file_bytes), strict=False)
        if getattr(reader, "is_encrypted", False):
            raise PDFExtractionError(
                "PDF is encrypted. Encrypted PDFs are not supported. "
                "Please use an unencrypted PDF."
            )

        parts: list[str] = []
        for page in getattr(reader, "pages", []):
            try:
                t = page.extract_text()
            except Exception:
                t = None
            if t:
                parts.append(t)
        return "\n".join(parts)
    except PDFExtractionError:
        raise
    except Exception:
        return ""


def _readability_score(text: str) -> float:
    if not text:
        return 0.0
    s = text.strip()
    if not s:
        return 0.0

    sample = s[:5000]
    lowered = sample.lower()
    if any(k in lowered for k in ['endobj', 'endstream', 'xref', 'trailer', 'obj', 'stream', '<<', '>>', '/type', '/font', '/resources']):
        return 0.0

    total = len(sample)
    printable = sum(1 for c in sample if c.isprintable() or c.isspace())
    printable_ratio = printable / max(1, total)
    if printable_ratio < 0.85:
        return 0.0

    whitespace_ratio = sum(1 for c in sample if c.isspace()) / max(1, total)
    if total >= 200 and whitespace_ratio < 0.02:
        return 0.0

    replacement_ratio = sample.count('\ufffd') / max(1, total)
    if replacement_ratio > 0.01:
        return 0.0

    non_space = [c for c in sample if not c.isspace()]
    if not non_space:
        return 0.0

    letters = sum(1 for c in non_space if c.isalpha())
    letters_ratio = letters / max(1, len(non_space))

    tokens = re.findall(r'\S+', sample)
    token_count = len(tokens)
    alpha_tokens = [t for t in tokens if any(ch.isalpha() for ch in t)]
    tokens_with_letters_ratio = len(alpha_tokens) / max(1, token_count)

    if len(alpha_tokens) >= 20:
        short_alpha_ratio = sum(1 for t in alpha_tokens if len(t) <= 2) / max(1, len(alpha_tokens))
        if short_alpha_ratio > 0.65:
            return 0.0
    long_alpha_ratio = sum(1 for t in alpha_tokens if len(t) >= 3) / max(1, len(alpha_tokens))

    weird = 0
    symbols = 0
    private_use = 0
    ascii_letters = 0
    devanagari_letters = 0
    gujarati_letters = 0
    other_letters = 0

    for c in non_space:
        o = ord(c)
        if 0xE000 <= o <= 0xF8FF or 0xF0000 <= o <= 0xFFFFD or 0x100000 <= o <= 0x10FFFD:
            private_use += 1
        if c.isalpha():
            if 0x41 <= o <= 0x5A or 0x61 <= o <= 0x7A:
                ascii_letters += 1
            elif 0x0900 <= o <= 0x097F:
                devanagari_letters += 1
            elif 0x0A80 <= o <= 0x0AFF:
                gujarati_letters += 1
            else:
                other_letters += 1
        elif not c.isdigit():
            weird += 1
            cat = unicodedata.category(c)
            if cat and cat[0] in ("S", "P") and c not in ".,;:!?-–—()[]{}'\"/\\@#%&*+=_":
                symbols += 1

    weird_ratio = weird / max(1, len(non_space))
    symbol_ratio = symbols / max(1, len(non_space))
    private_use_ratio = private_use / max(1, len(non_space))
    if symbol_ratio > 0.35:
        return 0.0

    total_letters = ascii_letters + devanagari_letters + gujarati_letters + other_letters
    if total_letters > 0:
        expected_ratio = (ascii_letters + devanagari_letters + gujarati_letters) / total_letters
    else:
        expected_ratio = 0.0

    score = 0.0
    score += 0.35 * printable_ratio
    score += 0.25 * min(1.0, letters_ratio / 0.55)
    score += 0.20 * min(1.0, tokens_with_letters_ratio / 0.70)
    score += 0.15 * expected_ratio
    score += 0.10 * min(1.0, long_alpha_ratio / 0.60)
    score -= 0.30 * weird_ratio
    score -= 0.25 * symbol_ratio
    score -= 0.70 * private_use_ratio

    if score < 0.0:
        return 0.0
    if score > 1.0:
        return 1.0
    return score


def _is_likely_scanned_pdf(pdf_text: str, extracted_text: str) -> bool:
    extracted = extracted_text.strip() if extracted_text else ""
    if extracted and len(extracted) > 100:
        return False
    lowered = pdf_text.lower()
    has_images = "/subtype /image" in lowered or "/image" in lowered or "/dctdecode" in lowered or "/jp" in lowered
    has_text_markers = "bt" in lowered and "et" in lowered
    if has_images and not extracted:
        return True
    if has_images and not has_text_markers and len(extracted) < 20:
        return True
    return False


def _ocr_text_from_pdf(file_bytes: bytes) -> str:
    try:
        import pytesseract  # type: ignore
    except Exception as e:
        raise PDFExtractionError(
            f"OCR is required for this PDF, but pytesseract is not available: {e}"
        )

    _configure_tesseract(pytesseract)
    if shutil.which("tesseract") is None and getattr(getattr(pytesseract, "pytesseract", None), "tesseract_cmd", None) is None:
        if platform.system().lower() == "windows":
            raise PDFExtractionError(
                "OCR is required for this PDF, but Tesseract is not installed or not in PATH. "
                "Install it with: winget install -e --id UB-Mannheim.TesseractOCR"
            )
        raise PDFExtractionError(
            "OCR is required for this PDF, but Tesseract is not installed or not in PATH."
        )

    images: list[object] = []

    try:
        import fitz  # type: ignore
        from PIL import Image  # type: ignore

        doc = fitz.open(stream=file_bytes, filetype="pdf")
        try:
            for page in doc:
                pix = page.get_pixmap(dpi=220)
                img = Image.open(io.BytesIO(pix.tobytes("png")))
                images.append(img)
        finally:
            doc.close()
    except Exception:
        images = []

    if not images:
        raise PDFExtractionError(
            "OCR is required for this PDF, but PDF-to-image conversion is not available. "
            "Install PyMuPDF and Pillow to enable OCR."
        )

    full_text_parts: list[str] = []
    langs_to_try = ["eng+hin+guj", "eng+hin", "eng"]
    for img in images:
        page_text = ""
        last_err: Optional[Exception] = None
        for lang in langs_to_try:
            try:
                page_text = pytesseract.image_to_string(img, lang=lang)
                break
            except Exception as e:
                last_err = e
                continue
        if not page_text and last_err is not None:
            raise PDFExtractionError(
                f"OCR failed. Ensure Tesseract is installed and available in PATH. Details: {last_err}"
            )
        if page_text:
            full_text_parts.append(page_text)
    return "\n\n".join(full_text_parts).strip()


def _extract_text_with_pymupdf_hybrid(file_bytes: bytes) -> Optional[tuple[str, str]]:
    try:
        import fitz  # type: ignore
    except Exception:
        return None

    try:
        doc = fitz.open(stream=file_bytes, filetype="pdf")
    except Exception:
        return None

    try:
        page_texts: list[str] = []
        page_methods: list[str] = []
        ocr_pages = 0
        text_pages = 0

        for page in doc:
            raw_text = ""
            try:
                raw_text = page.get_text("text") or ""
            except Exception:
                raw_text = ""

            text_norm = _normalize_text_for_preview(raw_text)
            score = _readability_score(text_norm)

            has_images = False
            try:
                has_images = len(page.get_images(full=True)) > 0
            except Exception:
                has_images = False

            needs_ocr = (not text_norm) or score < 0.55
            if not needs_ocr:
                page_texts.append(text_norm)
                page_methods.append("TEXT")
                text_pages += 1
                continue

            ocr_text = _ocr_text_from_pymupdf_page(page)
            ocr_norm = _normalize_text_for_preview(ocr_text)
            ocr_score = _readability_score(ocr_norm) if ocr_norm else 0.0

            chosen = ""
            method = "OCR"

            if ocr_norm and ocr_score >= 0.55:
                chosen = ocr_norm
                method = "OCR"

            if not chosen and has_images:
                raise PDFExtractionError("Scanned PDF detected but OCR returned no readable text.")
            if not chosen and not has_images:
                raise PDFExtractionError("Embedded fonts detected but OCR returned no readable text.")

            page_texts.append(chosen)
            page_methods.append(method)
            if method == "OCR":
                ocr_pages += 1
            else:
                text_pages += 1

        combined = "\n\n".join(t for t in page_texts if t.strip()).strip()
        if not combined:
            raise PDFExtractionError("Document contains no extractable text.")
        if _readability_score(combined) < 0.55:
            raise PDFExtractionError("Could not extract readable text from this PDF.")

        if ocr_pages == 0:
            return combined, "Text extraction applied (Text)"
        if text_pages == 0:
            return combined, "Scanned PDF detected — OCR applied (OCR)"

        return combined, f"Mixed PDF detected — OCR applied to {ocr_pages}/{ocr_pages + text_pages} pages (Hybrid)"
    finally:
        try:
            doc.close()
        except Exception:
            pass


def _ocr_text_from_pymupdf_page(page: object) -> str:
    try:
        import pytesseract  # type: ignore
    except Exception as e:
        raise PDFExtractionError(
            f"OCR is required for this PDF, but pytesseract is not available: {e}"
        )

    _configure_tesseract(pytesseract)
    if shutil.which("tesseract") is None and getattr(getattr(pytesseract, "pytesseract", None), "tesseract_cmd", None) is None:
        if platform.system().lower() == "windows":
            raise PDFExtractionError(
                "OCR is required for this PDF, but Tesseract is not installed or not in PATH. "
                "Install it with: winget install -e --id UB-Mannheim.TesseractOCR"
            )
        raise PDFExtractionError(
            "OCR is required for this PDF, but Tesseract is not installed or not in PATH."
        )

    try:
        from PIL import Image  # type: ignore
    except Exception as e:
        raise PDFExtractionError(
            f"OCR is required for this PDF, but Pillow is not available: {e}"
        )

    try:
        pix = page.get_pixmap(dpi=220)
        img = Image.open(io.BytesIO(pix.tobytes("png")))
    except Exception as e:
        raise PDFExtractionError(f"Failed to render page for OCR: {e}")

    langs_to_try = ["eng+hin+guj", "eng+hin", "eng"]
    last_err: Optional[Exception] = None
    for lang in langs_to_try:
        try:
            return pytesseract.image_to_string(img, lang=lang)
        except Exception as e:
            last_err = e
            continue

    raise PDFExtractionError(
        f"OCR failed. Ensure Tesseract is installed and available in PATH. Details: {last_err}"
    )



def _extract_text_streams(pdf_text: str) -> str:
    """
    Extract text content from PDF text streams.

    Searches for stream objects, decompresses if needed, and extracts strings.
    """
    extracted = []

    # Find all stream objects: stream ... endstream
    # These contain the actual content (may be compressed)
    stream_pattern = r'stream\s*(.*?)\s*endstream'
    
    for stream_match in re.finditer(stream_pattern, pdf_text, re.DOTALL):
        stream_bytes = stream_match.group(1)
        
        # Try to extract text from this stream
        stream_text = _extract_from_stream(stream_bytes, pdf_text, stream_match.start())
        if stream_text:
            extracted.append(stream_text)
    
    return ' '.join(extracted)


def _extract_from_stream(stream_data: str, pdf_text: str, stream_pos: int) -> str:
    """
    Extract text from a PDF stream object.
    Attempts decompression if the stream is compressed.
    """
    try:
        # Check if stream is FlateDecode compressed (look back for /FlateDecode)
        search_start = max(0, stream_pos - 500)
        preamble = pdf_text[search_start:stream_pos]
        is_compressed = '/FlateDecode' in preamble or '/Flate' in preamble
        
        decoded = None
        if is_compressed:
            # Try to decompress
            try:
                # Convert string to bytes for decompression
                stream_bytes = stream_data.encode('iso-8859-1', errors='ignore')
                decompressed = zlib.decompress(stream_bytes)
                # Decode decompressed content
                decoded = decompressed.decode('iso-8859-1', errors='ignore')
            except Exception:
                # If decompression fails, fall back to treating as raw text
                decoded = None
        
        if not decoded:
            # Plain text stream or decompression failed
            decoded = stream_data
        
        # Extract strings from decoded content
        # Look for: (text) strings and <hex> strings
        strings = []
        
        # Literal strings in parentheses
        literal_pattern = r'\(([^()]*)\)'
        for match in re.finditer(literal_pattern, decoded):
            s = match.group(1)
            s = _unescape_pdf_string(s)
            if s.strip() and len(s.strip()) > 1:
                strings.append(s)
        
        # Hex-encoded strings
        hex_pattern = r'<([0-9A-Fa-f]+)>'
        for match in re.finditer(hex_pattern, decoded):
            hex_str = match.group(1)
            try:
                if len(hex_str) % 2 == 1:
                    hex_str += '0'
                decoded_hex = _decode_pdf_bytes(bytes.fromhex(hex_str))
                if decoded_hex.strip() and len(decoded_hex.strip()) > 1:
                    strings.append(decoded_hex)
            except Exception:
                pass
        
        return ' '.join(strings) if strings else ''
    
    except Exception as e:
        logger.debug(f"Error extracting from stream: {e}")
        return ''



def _extract_strings_from_text_object(text_block: str) -> list:
    """
    Extract individual string objects from a text block.

    PDFs represent text as:
      - Literal strings: (Hello World) or (Hello\nWorld)
      - Hex strings: <48656C6C6F> (for binary/special chars)
    """
    strings = []

    # Pattern 1: Literal strings in parentheses: (text)
    # Handles escaped parentheses: \( \)
    literal_pattern = r'\(([^()\\]*(?:\\.[^()\\]*)*)\)'
    for match in re.finditer(literal_pattern, text_block):
        s = match.group(1)
        # Unescape common PDF escape sequences
        s = _unescape_pdf_string(s)
        if s.strip():
            strings.append(s)

    # Pattern 2: Hex strings: <HEXDATA>
    hex_pattern = r'<([0-9A-Fa-f]+)>'
    for match in re.finditer(hex_pattern, text_block):
        hex_str = match.group(1)
        try:
            # Decode hex to text
            # If odd number of chars, pad with 0
            if len(hex_str) % 2 == 1:
                hex_str += '0'
            decoded = _decode_pdf_bytes(bytes.fromhex(hex_str))
            if decoded.strip():
                strings.append(decoded)
        except Exception:
            # Silently skip malformed hex strings
            pass

    return strings


def _unescape_pdf_string(s: str) -> str:
    """
    Unescape common PDF escape sequences.

    Examples:
      \n -> newline
      \r -> carriage return
      \t -> tab
      \( -> (
      \) -> )
      \\ -> \
    """
    def _octal_repl(m: re.Match) -> str:
        try:
            return chr(int(m.group(1), 8))
        except Exception:
            return m.group(0)

    result = re.sub(r'\\([0-7]{1,3})', _octal_repl, s)

    # Map of escape sequences
    escapes = {
        r'\n': '\n',
        r'\r': '\r',
        r'\t': '\t',
        r'\f': '\f',
        r'\b': '\b',
        r'\\': '\\',
        r'\(': '(',
        r'\)': ')',
    }

    for escaped, unescaped in escapes.items():
        result = result.replace(escaped, unescaped)

    return result


def _decode_pdf_bytes(b: bytes) -> str:
    if not b:
        return ''
    if b.startswith(b'\xfe\xff'):
        try:
            return b[2:].decode('utf-16-be', errors='ignore')
        except Exception:
            pass
    if len(b) >= 4:
        zero_count = b.count(0)
        if zero_count >= len(b) // 4:
            try:
                return b.decode('utf-16-be', errors='ignore')
            except Exception:
                pass
    try:
        return b.decode('utf-8', errors='ignore')
    except Exception:
        return b.decode('iso-8859-1', errors='ignore')


def validate_pdf_simple(file_bytes: bytes) -> tuple[bool, str]:
    """
    Quick validation: check if PDF is likely to extract text successfully.

    Returns:
        (is_valid, message) tuple
    """
    try:
        if not file_bytes.startswith(b'%PDF'):
            return False, "Invalid PDF: missing %PDF header"

        pdf_text = file_bytes.decode('iso-8859-1', errors='ignore')

        if '/Encrypt' in pdf_text:
            return False, "Encrypted PDFs are not supported"

        if 'BT' not in pdf_text or 'ET' not in pdf_text:
            return False, (
                "PDF has no text streams (BT/ET markers). "
                "This is likely a scanned or image-based PDF."
            )

        return True, "PDF looks extractable"

    except Exception as e:
        return False, f"Error validating PDF: {e}"
