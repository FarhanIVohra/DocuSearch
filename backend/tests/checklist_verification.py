import os
import sys
import time
import io
import zipfile

# Ensure project root is on sys.path
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

from fastapi.testclient import TestClient
from backend.http_api import app

client = TestClient(app)

def _make_docx_bytes(text: str) -> bytes:
    buf = io.BytesIO()
    with zipfile.ZipFile(buf, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        zf.writestr(
            "[Content_Types].xml",
            """<?xml version="1.0" encoding="UTF-8"?>
<Types xmlns="http://schemas.openxmlformats.org/package/2006/content-types">
  <Default Extension="rels" ContentType="application/vnd.openxmlformats-package.relationships+xml"/>
  <Default Extension="xml" ContentType="application/xml"/>
  <Override PartName="/word/document.xml" ContentType="application/vnd.openxmlformats-officedocument.wordprocessingml.document.main+xml"/>
</Types>""",
        )
        zf.writestr(
            "_rels/.rels",
            """<?xml version="1.0" encoding="UTF-8"?>
<Relationships xmlns="http://schemas.openxmlformats.org/package/2006/relationships">
  <Relationship Id="rId1" Type="http://schemas.openxmlformats.org/officeDocument/2006/relationships/officeDocument" Target="word/document.xml"/>
</Relationships>""",
        )
        zf.writestr(
            "word/document.xml",
            f"""<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<w:document xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">
  <w:body>
    <w:p><w:r><w:t>{text}</w:t></w:r></w:p>
  </w:body>
</w:document>""",
        )
    return buf.getvalue()

print("=" * 70)
print("CHECKLIST VERIFICATION FOR SEARCH ENGINE FRONTEND READINESS")
print("=" * 70)

# Test 1: Upload .docx works every time
print("\n[1] Testing: Upload .docx works every time")
doc_text_1 = "Search engines index documents. Search indexing works."
try:
    docx_bytes = _make_docx_bytes(doc_text_1)
    files = {
        "file": (
            "doc1.docx",
            docx_bytes,
            "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        )
    }
    r1 = client.post('/upload', files=files)
    
    r2 = client.post('/upload', files=files)
    
    if r1.status_code == 200 and r2.status_code == 200:
        print("‚úÖ Upload .docx works every time")
        upload_ok = True
    else:
        print(f"‚ùå Upload failed: r1={r1.status_code}, r2={r2.status_code}")
        upload_ok = False
except Exception as e:
    print(f"‚ùå Upload error: {e}")
    upload_ok = False

# Test 2: Search highlights correct words (positions match query)
print("\n[2] Testing: Search highlights correct words")
try:
    r = client.get('/search', params={'q': 'search engines'})
    data = r.json()
    
    # Verify positions are returned
    has_positions = False
    if data.get('matches'):
        for match in data['matches']:
            if match.get('positions') and len(match['positions']) > 0:
                has_positions = True
                term = match['term']
                pos = match['positions'][0]
                # Read uploaded doc to verify positions are correct
                if pos < len(doc_text_1):
                    actual_text = doc_text_1[pos:pos+len(term)]
                    if actual_text.lower() == term.lower():
                        print(f"‚úÖ Highlight position valid: '{term}' at position {pos}")
                    else:
                        print(f"‚ö†Ô∏è  Position mismatch: expected '{term}' at {pos}, got '{actual_text}'")
    
    if has_positions and data.get('total_matches', 0) > 0:
        print("‚úÖ Search highlights correct words (positions provided)")
        highlight_ok = True
    else:
        print(f"‚ùå No position data: matches={data.get('matches')}")
        highlight_ok = False
except Exception as e:
    print(f"‚ùå Highlight test error: {e}")
    highlight_ok = False

# Test 3: Cache HIT is visible on repeat search
print("\n[3] Testing: Cache HIT is visible on repeat search")
try:
    r1 = client.get('/search', params={'q': 'indexing'})
    data1 = r1.json()
    
    r2 = client.get('/search', params={'q': 'indexing'})
    data2 = r2.json()
    
    if data1.get('cache') == 'MISS' and data2.get('cache') == 'HIT':
        print(f"‚úÖ Cache HIT visible: First={data1['cache']}, Second={data2['cache']}")
        print(f"   Time: MISS={data1['time_ms']:.3f}ms, HIT={data2['time_ms']:.3f}ms")
        cache_ok = True
    else:
        print(f"‚ùå Cache not working: First={data1.get('cache')}, Second={data2.get('cache')}")
        cache_ok = False
except Exception as e:
    print(f"‚ùå Cache test error: {e}")
    cache_ok = False

# Test 4: Page reload + re-upload still works
print("\n[4] Testing: Page reload + re-upload still works")
try:
    # Simulate page reload by uploading a different file
    doc_text_2 = "Indexing is the backbone of search."
    docx_bytes_2 = _make_docx_bytes(doc_text_2)
    files2 = {
        "file": (
            "doc2.docx",
            docx_bytes_2,
            "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        )
    }
    r_upload = client.post('/upload', files=files2)
    
    if r_upload.status_code == 200:
        # Try to search in the new document
        r_search = client.get('/search', params={'q': 'backbone'})
        if r_search.status_code == 200:
            data = r_search.json()
            if data.get('total_matches', 0) > 0:
                print("‚úÖ Page reload + re-upload works (cache cleared, new doc searchable)")
                reload_ok = True
            else:
                print(f"‚ö†Ô∏è  Re-upload OK but search returned {data.get('total_matches')} matches")
                reload_ok = True  # Upload succeeded, query just has no matches
        else:
            print(f"‚ùå Search after re-upload failed: {r_search.status_code}")
            reload_ok = False
    else:
        print(f"‚ùå Re-upload failed: {r_upload.status_code}")
        reload_ok = False
except Exception as e:
    print(f"‚ùå Reload test error: {e}")
    reload_ok = False

# Test 5: Demo runs in under 2 minutes
print("\n[5] Testing: Demo runs in under 2 minutes")
try:
    # Measure full upload + 10 searches cycle
    start = time.time()

    doc_text_perf = "Search engines index documents. Search indexing works completely."
    docx_bytes_perf = _make_docx_bytes(doc_text_perf)
    files = {
        "file": (
            "perf.docx",
            docx_bytes_perf,
            "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        )
    }
    client.post('/upload', files=files)
    
    queries = ['search', 'engines', 'indexing', 'working', 'document', 
               'search', 'how', 'working', 'engines', 'completely']
    
    for q in queries:
        client.get('/search', params={'q': q})
    
    elapsed = time.time() - start
    
    if elapsed < 120:  # 2 minutes = 120 seconds
        print(f"‚úÖ Demo runs in under 2 minutes: {elapsed:.2f}s")
        perf_ok = True
    else:
        print(f"‚ùå Demo too slow: {elapsed:.2f}s (> 120s)")
        perf_ok = False
except Exception as e:
    print(f"‚ùå Performance test error: {e}")
    perf_ok = False

# Summary
print("\n" + "=" * 70)
print("FINAL CHECKLIST:")
print("=" * 70)
all_ok = upload_ok and highlight_ok and cache_ok and reload_ok and perf_ok
checks = [
    ("Upload .docx works every time", upload_ok),
    ("Search highlights correct words", highlight_ok),
    ("Cache HIT is visible on repeat search", cache_ok),
    ("Page reload + re-upload still works", reload_ok),
    ("Demo runs in under 2 minutes", perf_ok),
]

for desc, status in checks:
    icon = "‚úÖ" if status else "‚ùå"
    print(f"{icon} {desc}")

print("\n" + "=" * 70)
if all_ok:
    print("üéâ ALL CHECKS PASSED - FRONTEND IS READY!")
else:
    print("‚ö†Ô∏è  Some checks failed - review above for details.")
print("=" * 70)
